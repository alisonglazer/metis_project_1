{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Reading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['180113', '180414', '190112', '190413']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the weeks to retrieve from the MTA database\n",
    "def list_weeks(list_of_dates):\n",
    "    weeks = []\n",
    "    for date in list_of_dates:\n",
    "        week_string = date.strftime('%y%m%d')\n",
    "        weeks.append(week_string)\n",
    "    return weeks        \n",
    "\n",
    "# We want to pull in data from a week in mid-January and mid-May of 2018 and 2019\n",
    "dates = [dt.datetime(2018,1,13),dt.datetime(2018,4,14),dt.datetime(2019,1,12),dt.datetime(2019,4,13)]\n",
    "weeks = list_weeks(dates)\n",
    "weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data for the desired weeks\n",
    "def readTurnstileData(week_string):\n",
    "    \"\"\"\n",
    "    This function reads in data from an online MTA Turnstile dataset into a DataFrame\n",
    "    ---\n",
    "    input: link to dataset\n",
    "    output: DataFrame\n",
    "    \"\"\"\n",
    "    cols = ['control_area','unit','scp','station','line_name','division','date','time',\n",
    "        'desc','entries','exits']\n",
    "    \n",
    "    link = 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_' + week_string + '.txt'\n",
    "    turnstile_data = pd.read_csv(link, header = 0, names = cols)\n",
    "    return turnstile_data\n",
    "\n",
    "# Create a single DataFrame containing all weeks\n",
    "def createTurnstileDataFrame(list_of_weeks):\n",
    "    df = pd.DataFrame()\n",
    "    df_chunk_list = []\n",
    "    for date in list_of_weeks:\n",
    "        df_chunk = readTurnstileData(date)\n",
    "        df_chunk_list.append(df_chunk)\n",
    "    df = pd.concat(df_chunk_list)\n",
    "    return df\n",
    "\n",
    "# Clean up date/time info\n",
    "def formatDateTime(df):\n",
    "    \"\"\"\n",
    "    This function converts the date and time into DateTime format in a single column\n",
    "    and deletes the unformatted date and time columns\n",
    "    \n",
    "    Note: only run once per DataFrame, will result in error otherwise\n",
    "    ---\n",
    "    input: DataFrame\n",
    "    output: DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    #convert date and time to DateTime format in a single column\n",
    "    df['concat_date_time'] = df['date'] + ' ' + df['time']\n",
    "    df['date_time'] = pd.to_datetime(df.concat_date_time,format = '%m/%d/%Y %H:%M:%S')\n",
    "    \n",
    "    #delete unformatted date and time columns\n",
    "    del df['concat_date_time']\n",
    "    del df['date']\n",
    "    del df['time']\n",
    "    return df\n",
    "\n",
    "def read_and_format_turnstile_data(list_of_weeks):\n",
    "    \"\"\"\n",
    "    This function reads in Turnstile data from online and returns a DataFrame with \n",
    "    with the date and time information converted to a single DateTime column\n",
    "    ---\n",
    "    input: link\n",
    "    output: DataFrame\n",
    "    \"\"\"\n",
    "    df = createTurnstileDataFrame(list_of_weeks)\n",
    "    df = formatDateTime(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data from the specified weeks\n",
    "orig_df = read_and_format_turnstile_data(weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw data to access easily later\n",
    "with open('data/orig_df.pickle', 'wb') as to_write:\n",
    "    pickle.dump(orig_df, to_write)\n",
    "del orig_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.5: read in data from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data from the pickle file if you are starting here\n",
    "# If you started from the beginning of the notebook, comment out the code below\n",
    "\n",
    "with open('data/orig_df.pickle','rb') as read_file:\n",
    "    orig_df = pickle.load(read_file)\n",
    "df = orig_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Organizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset indexing on the DataFrame\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column for weekday\n",
    "df['weekday'] = df[['date_time']].apply(lambda x: x['date_time'].dayofweek,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column for year\n",
    "df['year'] = df[['date_time']].apply(lambda x: x['date_time'].year,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column for the time of day\n",
    "df['hour'] = df[['date_time']].apply(lambda x: x['date_time'].hour,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column with unique ID for each turnstile\n",
    "df['turnstile_id'] = df.groupby(['control_area','unit','scp','station','year']).ngroup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort DataFrame by turnstile and date\n",
    "df.sort_values(['turnstile_id','date_time'],inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Find entries and exits differences per turnstile\n",
    "df['exit_counts'] = abs(df.groupby('turnstile_id').exits.diff())\n",
    "df['entry_counts'] = abs(df.groupby('turnstile_id').entries.diff())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>entries</th>\n",
       "      <th>exits</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>turnstile_id</th>\n",
       "      <th>exit_counts</th>\n",
       "      <th>entry_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>803510.000000</td>\n",
       "      <td>8.035100e+05</td>\n",
       "      <td>8.035100e+05</td>\n",
       "      <td>803510.000000</td>\n",
       "      <td>803510.000000</td>\n",
       "      <td>803510.000000</td>\n",
       "      <td>803510.000000</td>\n",
       "      <td>7.938810e+05</td>\n",
       "      <td>7.938810e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>100458.892432</td>\n",
       "      <td>4.005398e+07</td>\n",
       "      <td>3.301926e+07</td>\n",
       "      <td>2.990372</td>\n",
       "      <td>2018.505035</td>\n",
       "      <td>11.113836</td>\n",
       "      <td>4815.938751</td>\n",
       "      <td>3.928604e+04</td>\n",
       "      <td>4.588957e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>58024.034431</td>\n",
       "      <td>2.076849e+08</td>\n",
       "      <td>1.924742e+08</td>\n",
       "      <td>1.995281</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>6.919003</td>\n",
       "      <td>2785.148550</td>\n",
       "      <td>6.777609e+06</td>\n",
       "      <td>7.113515e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>50219.000000</td>\n",
       "      <td>4.587942e+05</td>\n",
       "      <td>2.128798e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>100438.000000</td>\n",
       "      <td>2.454182e+06</td>\n",
       "      <td>1.389020e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4799.000000</td>\n",
       "      <td>5.100000e+01</td>\n",
       "      <td>7.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>150657.750000</td>\n",
       "      <td>6.860751e+06</td>\n",
       "      <td>4.788484e+06</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>7231.000000</td>\n",
       "      <td>1.670000e+02</td>\n",
       "      <td>2.450000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>204710.000000</td>\n",
       "      <td>2.130144e+09</td>\n",
       "      <td>2.124178e+09</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>9628.000000</td>\n",
       "      <td>2.107450e+09</td>\n",
       "      <td>2.088571e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index       entries         exits        weekday  \\\n",
       "count  803510.000000  8.035100e+05  8.035100e+05  803510.000000   \n",
       "mean   100458.892432  4.005398e+07  3.301926e+07       2.990372   \n",
       "std     58024.034431  2.076849e+08  1.924742e+08       1.995281   \n",
       "min         0.000000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%     50219.000000  4.587942e+05  2.128798e+05       1.000000   \n",
       "50%    100438.000000  2.454182e+06  1.389020e+06       3.000000   \n",
       "75%    150657.750000  6.860751e+06  4.788484e+06       5.000000   \n",
       "max    204710.000000  2.130144e+09  2.124178e+09       6.000000   \n",
       "\n",
       "                year           hour   turnstile_id   exit_counts  entry_counts  \n",
       "count  803510.000000  803510.000000  803510.000000  7.938810e+05  7.938810e+05  \n",
       "mean     2018.505035      11.113836    4815.938751  3.928604e+04  4.588957e+04  \n",
       "std         0.499975       6.919003    2785.148550  6.777609e+06  7.113515e+06  \n",
       "min      2018.000000       0.000000       0.000000  0.000000e+00  0.000000e+00  \n",
       "25%      2018.000000       5.000000    2409.000000  8.000000e+00  1.000000e+01  \n",
       "50%      2019.000000      11.000000    4799.000000  5.100000e+01  7.400000e+01  \n",
       "75%      2019.000000      17.000000    7231.000000  1.670000e+02  2.450000e+02  \n",
       "max      2019.000000      23.000000    9628.000000  2.107450e+09  2.088571e+09  "
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max values on exit and entry counts are way too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOutliers(df,column):\n",
    "    \"\"\"\n",
    "    Returns outliers above the max limit for a column in a dataframe\n",
    "    Adjust outlier cutoff to q75 + 4*iqr to include more data\n",
    "    ---\n",
    "    input: DataFrame, column\n",
    "    output: DataFrame\n",
    "    \"\"\"\n",
    "    q25,q50,q75 = df[column].quantile(q=[0.25,0.5,0.75])\n",
    "    iqr = q75-q25\n",
    "    #max limits to be considered an outlier\n",
    "    max = q75 + 4*iqr\n",
    "    #identify the points\n",
    "    outlier_mask = [True if x > max else False for x in df[column]]\n",
    "    print('{} outliers found out of {} data points, {}% of the data'.format(sum(outlier_mask),len(df[column]),100*(sum(outlier_mask)/len(df[column]))))\n",
    "    return outlier_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry: \n",
      "17089 outliers found out of 803510 data points, 2.1267936926733952% of the data\n",
      "786421 points left after removing entry_counts outlier points\n",
      "\n",
      "Exit:\n",
      "26722 outliers found out of 803510 data points, 3.325658672574081% of the data\n",
      "776788 points left after removing exit_counts outlier points\n"
     ]
    }
   ],
   "source": [
    "#Get outliers for entries\n",
    "print('Entry: ')\n",
    "df['entry_outliers'] = findOutliers(df,'entry_counts')\n",
    "\n",
    "#DataFrame with entry outliers removed\n",
    "clean_df_entries = df.loc[~df['entry_outliers']]\n",
    "print('{} points left after removing entry_counts outlier points'.format(clean_df_entries.shape[0]))\n",
    "\n",
    "#Get outliers for exits\n",
    "print('\\nExit:')\n",
    "df['exit_outliers'] = findOutliers(df,'exit_counts')\n",
    "\n",
    "#DataFrame with exit outliers removed\n",
    "clean_df_exits = df.loc[~df['exit_outliers']]\n",
    "print('{} points left after removing exit_counts outlier points'.format(clean_df_exits.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776792 points left after removing entry_counts NaN values\n",
      "776788 points left after removing entry_counts NaN values\n"
     ]
    }
   ],
   "source": [
    "# Eliminate Null values\n",
    "# Delete rows with null values for entry_counts\n",
    "clean_df_entries = clean_df_entries[~clean_df_entries.entry_counts.isnull()]\n",
    "print('{} points left after removing entry_counts NaN values'.format(clean_df_entries.shape[0]))\n",
    "\n",
    "# Delete rows with null values for exit_counts\n",
    "clean_df_entries = clean_df_entries[~clean_df_entries.exit_counts.isnull()]\n",
    "print('{} points left after removing entry_counts NaN values'.format(clean_df_exits.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames\n",
    "clean_df = clean_df_entries.merge(clean_df_exits,left_on=list(clean_df_entries.columns), \\\n",
    "                                  right_on=list(clean_df_exits.columns),how='inner')\n",
    "#Add a column for total traffic at each turnstile\n",
    "clean_df['total_traffic'] = clean_df['entry_counts'] + clean_df['exit_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748226 rows left after cleaning the data, 93.11968737165685% of the original\n"
     ]
    }
   ],
   "source": [
    "print('{} rows left after cleaning the data, {}% of the original'.format(clean_df.shape[0],100*(clean_df.shape[0]/df.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete outlier ID columns\n",
    "# Only run this cell once\n",
    "del clean_df['entry_outliers']\n",
    "del clean_df['exit_outliers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data to access easily later\n",
    "with open('data/clean_df.pickle', 'wb') as to_write:\n",
    "    pickle.dump(clean_df, to_write)\n",
    "\n",
    "del clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.5: Read in the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data from the pickle file if you are starting here\n",
    "# If you started from the beginning of the notebook, comment out the code below\n",
    "\n",
    "with open('data/clean_df.pickle','rb') as read_file:\n",
    "    clean_df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>control_area</th>\n",
       "      <th>unit</th>\n",
       "      <th>scp</th>\n",
       "      <th>station</th>\n",
       "      <th>line_name</th>\n",
       "      <th>division</th>\n",
       "      <th>desc</th>\n",
       "      <th>entries</th>\n",
       "      <th>exits</th>\n",
       "      <th>date_time</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>turnstile_id</th>\n",
       "      <th>exit_counts</th>\n",
       "      <th>entry_counts</th>\n",
       "      <th>total_traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6470223</td>\n",
       "      <td>2190140</td>\n",
       "      <td>2018-01-06 07:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6470256</td>\n",
       "      <td>2190229</td>\n",
       "      <td>2018-01-06 11:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6470379</td>\n",
       "      <td>2190299</td>\n",
       "      <td>2018-01-06 15:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6470665</td>\n",
       "      <td>2190366</td>\n",
       "      <td>2018-01-06 19:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6470809</td>\n",
       "      <td>2190398</td>\n",
       "      <td>2018-01-06 23:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>748221</td>\n",
       "      <td>204706</td>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>374</td>\n",
       "      <td>2019-04-12 05:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>9628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>748222</td>\n",
       "      <td>204707</td>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>374</td>\n",
       "      <td>2019-04-12 09:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>9628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>748223</td>\n",
       "      <td>204708</td>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>374</td>\n",
       "      <td>2019-04-12 13:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>9628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>748224</td>\n",
       "      <td>204709</td>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>374</td>\n",
       "      <td>2019-04-12 17:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>9628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>748225</td>\n",
       "      <td>204710</td>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>374</td>\n",
       "      <td>2019-04-12 21:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>9628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748226 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index control_area  unit       scp        station line_name division  \\\n",
       "0            1         A002  R051  02-00-00          59 ST   NQR456W      BMT   \n",
       "1            2         A002  R051  02-00-00          59 ST   NQR456W      BMT   \n",
       "2            3         A002  R051  02-00-00          59 ST   NQR456W      BMT   \n",
       "3            4         A002  R051  02-00-00          59 ST   NQR456W      BMT   \n",
       "4            5         A002  R051  02-00-00          59 ST   NQR456W      BMT   \n",
       "...        ...          ...   ...       ...            ...       ...      ...   \n",
       "748221  204706        TRAM2  R469  00-05-01  RIT-ROOSEVELT         R      RIT   \n",
       "748222  204707        TRAM2  R469  00-05-01  RIT-ROOSEVELT         R      RIT   \n",
       "748223  204708        TRAM2  R469  00-05-01  RIT-ROOSEVELT         R      RIT   \n",
       "748224  204709        TRAM2  R469  00-05-01  RIT-ROOSEVELT         R      RIT   \n",
       "748225  204710        TRAM2  R469  00-05-01  RIT-ROOSEVELT         R      RIT   \n",
       "\n",
       "           desc  entries    exits           date_time  weekday  year  hour  \\\n",
       "0       REGULAR  6470223  2190140 2018-01-06 07:00:00        5  2018     7   \n",
       "1       REGULAR  6470256  2190229 2018-01-06 11:00:00        5  2018    11   \n",
       "2       REGULAR  6470379  2190299 2018-01-06 15:00:00        5  2018    15   \n",
       "3       REGULAR  6470665  2190366 2018-01-06 19:00:00        5  2018    19   \n",
       "4       REGULAR  6470809  2190398 2018-01-06 23:00:00        5  2018    23   \n",
       "...         ...      ...      ...                 ...      ...   ...   ...   \n",
       "748221  REGULAR     5554      374 2019-04-12 05:00:00        4  2019     5   \n",
       "748222  REGULAR     5554      374 2019-04-12 09:00:00        4  2019     9   \n",
       "748223  REGULAR     5554      374 2019-04-12 13:00:00        4  2019    13   \n",
       "748224  REGULAR     5554      374 2019-04-12 17:00:00        4  2019    17   \n",
       "748225  REGULAR     5554      374 2019-04-12 21:00:00        4  2019    21   \n",
       "\n",
       "        turnstile_id  exit_counts  entry_counts  total_traffic  \n",
       "0                  0         17.0           7.0           24.0  \n",
       "1                  0         89.0          33.0          122.0  \n",
       "2                  0         70.0         123.0          193.0  \n",
       "3                  0         67.0         286.0          353.0  \n",
       "4                  0         32.0         144.0          176.0  \n",
       "...              ...          ...           ...            ...  \n",
       "748221          9628          0.0           0.0            0.0  \n",
       "748222          9628          0.0           0.0            0.0  \n",
       "748223          9628          0.0           0.0            0.0  \n",
       "748224          9628          0.0           0.0            0.0  \n",
       "748225          9628          0.0           0.0            0.0  \n",
       "\n",
       "[748226 rows x 18 columns]"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Data\n",
    "\n",
    "- Which station has the most foot traffic:\n",
    "    - On weekdays in particular?\n",
    "    - On which days?\n",
    "    - At what times?\n",
    "\n",
    "\n",
    "- Which stations are near college campuses?\n",
    "- Which stations are in tech-heavy areas?\n",
    "- Which stations are in wealthy neighborhoods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_groupby = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_groupby = turnstile_data.groupby('station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station\n",
       "NEWARK HM HE            1073019\n",
       "PATH WTC 2              7402804\n",
       "NEWARK HW BMEBE        16359580\n",
       "9TH STREET             18546632\n",
       "ORCHARD BEACH          20787564\n",
       "                       ...     \n",
       "DEKALB AV          226731273077\n",
       "23 ST              237675376663\n",
       "TIMES SQ-42 ST     244851205878\n",
       "125 ST             282278333960\n",
       "42 ST-PORT AUTH    315905669087\n",
       "Name: entries, Length: 378, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_entries = station_groupby.entries.sum().sort_values(ascending = True)\n",
    "station_entries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
